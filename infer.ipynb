{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import TransformerVAE\n",
    "from dataset import SMILESDataset\n",
    "from utils import tokenize, pad_sequence, create_vocab, calculate_max_len\n",
    "from cfg import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model, input_sequence, vocab, max_len, device):\n",
    "    # Create index to char mapping\n",
    "    index_to_char = {idx: char for char, idx in vocab.items()}\n",
    "    \n",
    "    # Tokenize and pad the input sequence\n",
    "    tokens = tokenize(input_sequence, vocab)\n",
    "    input_ids = pad_sequence(tokens, max_len, vocab[\"<pad>\"])\n",
    "    input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    \n",
    "    # Create attention mask\n",
    "    attention_mask = [1 if token != vocab[\"<pad>\"] else 0 for token in input_ids[0]]\n",
    "    attention_mask = torch.tensor(attention_mask).unsqueeze(0).to(device)  # Add batch dimension\n",
    "    \n",
    "    # Perform inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits, _, _ = model(input_ids, attention_mask)\n",
    "    \n",
    "    # Get the predicted sequence\n",
    "    predicted_ids = logits.argmax(dim=-1).squeeze(0).tolist()\n",
    "    \n",
    "    # Convert predicted IDs back to SMILES string\n",
    "    predicted_sequence = ''.join([index_to_char.get(idx, '<unk>') for idx in predicted_ids if idx != vocab[\"<pad>\"]])\n",
    "    \n",
    "    return predicted_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence: C.CCCO ~ O=O > CC(=O)C(C)=O ~ [OH-]\n",
      "Predicted Sequence: C.CCCO ~ O=O > CC(=O)C(C)=O ~ [OH-]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load configuration\n",
    "    config = Config()\n",
    "    \n",
    "    # Load dataset to get vocab and max_len\n",
    "    dataset = SMILESDataset(config.filepath)\n",
    "    vocab = dataset.vocab\n",
    "    max_len = dataset.max_len\n",
    "    \n",
    "    # Load the trained model\n",
    "    model = TransformerVAE(\n",
    "        vocab_size=len(vocab),\n",
    "        embedding_dim=config.input_dim,\n",
    "        hidden_dim=config.hidden_dim,\n",
    "        latent_dim=config.latent_dim,\n",
    "        num_heads=config.num_heads,\n",
    "        num_layers=config.num_layers,\n",
    "        dropout=config.dropout\n",
    "    ).to(config.device)\n",
    "    \n",
    "    # Load the best model weights\n",
    "    checkpoint_dir = \"./checkpoints/20241126-0919\"  # Replace with your checkpoint directory\n",
    "    model.load_state_dict(torch.load(f\"{checkpoint_dir}/best_model.pth\", weights_only=True))\n",
    "    \n",
    "    # Example input sequence\n",
    "    input_sequence = \"C.CCCO ~ O=O > CC(=O)C(C)=O ~ [OH-]\"  # Replace with your input SMILES string\n",
    "    \n",
    "    # Perform inference\n",
    "    predicted_sequence = infer(model, input_sequence, vocab, max_len, config.device)\n",
    "    \n",
    "    print(f\"Input Sequence: {input_sequence}\")\n",
    "    print(f\"Predicted Sequence: {predicted_sequence}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
